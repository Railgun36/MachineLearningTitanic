{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Prediction of Survivers - Dataset: Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, svm\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df_sub = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "sns.heatmap(corr)\n",
    "print(corr[[\"Age\",\"Survived\"]].sort_values(by=\"Survived\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL = [\"PassengerId\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Survived\", \"Pclass\"]\n",
    "CATEGORIAL = [\"Name\", \"Embarked\", \"Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(dataframe):\n",
    "        \n",
    "    dataframe[\"duplicate\"] = dataframe.duplicated() # remove duplicates\n",
    "    dataframe = dataframe.drop(dataframe[dataframe[\"duplicate\"]==True].index)\n",
    "    dataframe.drop(columns=[\"duplicate\"])\n",
    "\n",
    "    dataframe = dataframe.drop(dataframe[dataframe[\"Sex\"]==29.69911764705882].index) # removed 1 invalid Datapoint Sex=29.XXXXX\n",
    "    \n",
    "    dataframe = dataframe.drop(dataframe[~dataframe[\"Embarked\"].isin([\"S\", \"C\", \"Q\"])].index) # removed 3 Datapoints nan from Embarked\n",
    "\n",
    "    for cat in CATEGORIAL: # Encode Categoricals\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        dataframe[cat] = le.fit_transform(dataframe[cat])\n",
    "    \n",
    "    for pclass in dataframe[\"Pclass\"].unique(): # Für NaN Alter: Mean der Pklassen (da höchste Korrelation)\n",
    "        dataframe.loc[((dataframe[\"Age\"].isnull()) & (dataframe[\"Pclass\"]==pclass)), \"Age\"] = dataframe.loc[dataframe[\"Pclass\"]==pclass, \"Age\"].mean()\n",
    "        print(pclass, dataframe.loc[dataframe[\"Pclass\"]==pclass, \"Age\"].mean())\n",
    "        dataframe.loc[((dataframe[\"Fare\"].isnull()) & (dataframe[\"Pclass\"]==pclass)), \"Fare\"] = dataframe.loc[dataframe[\"Pclass\"]==pclass, \"Fare\"].mean()\n",
    "    \n",
    "    # Alternativ: fill Nan Age with mean\n",
    "    #dataframe[dataframe[\"Age\"].isnull()] = dataframe[\"Age\"].mean()\n",
    "    \n",
    "    dataframe.drop(columns=[\"Cabin\"]) # Cabin raus - da nur 1/4 der Daten vorhanden\n",
    "    dataframe.drop(columns=[\"Name\"]) # Name raus \n",
    "     \n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "df = clean(df)\n",
    "df_sub = clean(df_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature \"Sex\" might be important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survived = df[[\"Sex\", \"Survived\"]].copy()\n",
    "sns.histplot(data=df_survived, x=\"Sex\", hue=\"Sex\", bins=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with train_test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df[[\"Sex\", \"Age\", \"Fare\", \"Pclass\", \"Embarked\"]].copy()\n",
    "y = df[\"Survived\"].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1, random_state=20) # Support Vector Classifier\n",
    "scores = cross_val_score(clf, X, y, cv=5) # 5 consecutive Times\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest with train_test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=3, criterion=\"gini\", random_state=20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest with Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=3, criterion=\"gini\", random_state=20)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stick to best result für test-data: SVM with train_test-split + wirte Upload-CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[[\"Sex\", \"Age\", \"Fare\", \"Pclass\", \"Embarked\"]].copy()\n",
    "y_train = df[\"Survived\"].copy()\n",
    "X_test = df_sub[[\"Sex\", \"Age\", \"Fare\", \"Pclass\", \"Embarked\"]].copy()\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdy = pd.DataFrame()\n",
    "df_rdy[\"PassengerId\"] = df_sub[\"PassengerId\"].copy()\n",
    "df_rdy[\"Survived\"] = y_pred\n",
    "df_rdy.to_csv(\"submit.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6fbf56dae6cf57b21ee1a7406971e3443db4aafb2a9cd27dd86369bbceace315"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
